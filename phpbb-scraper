#!/bin/bash
# by Dominik Stanis≈Çaw Suchora <suchora.dominik7@gmail.com>
# License: GNU GPLv3

shopt -s extglob

declare maxprocs='1' url _cookies

IFS=$'\n'

ucurl() {
    curl -k -L -g -m 120 -s -b "$_cookies" --user-agent 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.15.2 Chrome/87.0.4280.144 Safari/537.36' -H 'Accept-Encoding: gzip, deflate' --compressed "$@"
}

get_topic() {
    [[ "$1" =~ ^http[s]?://([[:alnum:]-]+\.)+[[:alpha:]]+/(.*/)?viewtopic\.php(.*)[\&\?]t=([[:digit:]]+) ]] || { echo "improper url - $1"; return; }
    local -r id="${BASH_REMATCH[4]}"
    [ -e "$id" ] && return
    echo "$1" >&2
    local t="$(ucurl "$1" | tr -d '\t\n\r\a\v')" t2
    local next path

    {
    echo "$1" #link
    echo "$id" #id
    echo "$(hgrep 'div #page-body; h[1-6] @l[1]; a href="\./viewtopic\.php.*" | "%i\n"' <<< "$t")" #title
    echo "$(hgrep 'ul #nav-breadcrumbs; a; span itemprop | "%i\t", div #page-header; li .icon-home; a | "%i\t"' <<< "$t")" #path
    while :
    do
        for i in $(hgrep 'div #page-body; div id="p[0-9]*" | "%t\n"' <<< "$t")
        do
            {
            echo "$(hgrep 'div id="p[0-9]*" @l[0] | "%(id)a\n"' <<< "$i" | sed 's/^p//')" #postid
            echo "$(hgrep 'p .author | "%i\n"' <<< "$i" | sed -E 's/.*>//; s/.*;//; s/^ *//; s/^([a-z]* )+//')" #date
            echo "$(hgrep 'div .content | "%i\n"' <<< "$i")" #content
            echo "$(hgrep 'div .signature #sig[0-9]* | "%i\n"' <<< "$i")" #signature
            echo "$(hgrep 'dl .postprofile #profile[0-9]*; dt @l[1]; img src | "%(src)a\n"' <<< "$i")" #avatar
            echo "$(hgrep 'dl .postprofile #profile[0-9]*; dt @l[1]; a @M"<" | "%i\n"' <<< "$i")" #user
            echo "$(hgrep 'dl .postprofile #profile[0-9]*; dt @l[1]; a href @M"<" | "%(href)a\n"' <<< "$i" | sed -E 's/.*[&;]u=([0-9]+).*/\1/')" #userid
            echo "$(hgrep 'dl .postprofile #profile[0-9]*; dd @l[1] @M"^&nbsp;$" | "%i\n"' <<< "$i" | sed -E 's/<strong>([^<]*)<\/strong>/\1/g; s/ +:/:/; /<ul [^>]*class="profile-icons">/{s/.*<a href="([^"]*)" title="Site [^"]*".*/Site\1/;t;d}; /^[^<>]+:/!{s/^/Rank:/};s/: *//' | paste -sd '\v')" #userinfo
            } | paste -sd '\t'
        done

        t2="$(hgrep 'a href rel=next | "%(href)a\n"' <<< "$t" | sed 's/^\.\///;s/&amp;/\&/g;q')"
        [ -z "$t2" ] && t2="$(hgrep -E 'div .topic-actions; div .pagination @l[1]; span @l[1]; (a|strong) -href=# | "%(href)a\n"' <<< "$t" | sed -n '/^$/{N;s/\n//;s/&amp;/\&/g;s/^\.\///;p;q}')"
        next="$url/$t2"
        grep -q '&start=[0-9]*$' <<< "$next" || break
        echo "$next" >&2
        t="$(ucurl "$next" | tr -d '\t\n\r\a\v')"
    done
    } | jq -RnMcs '
        (inputs | split("\n")) as $lines |
        .["link"]=$lines[0] |
        .["id"]=$lines[1] |
        .["title"]=$lines[2] |
        .["path"]=($lines[3] | split("\t"))[:-1] |
        .["posts"]=($lines[4:-1] | map(split("\t") | {
            ("postid"):.[0],
            ("date"):.[1],
            ("content"):.[2],
            ("signature"):.[3],
            ("avatar"):.[4],
            ("user"):.[5],
            ("userid"):(.[6]),
            ("userinfo"):(.[7] | split("") | map( split("") | {
                ("key"):.[0],
                ("value"):.[1]
            }))
        }))' > "$id"
}

#get_topic_1() {
#    #[[ "$1" =~ ^http[s]?://([[:alnum:]-]+\.)+[[:alpha:]]+/(.*/)?viewtopic\.php(.*)[\&\?]t=([[:digit:]]+) ]] || { echo "improper url - $1"; return; }
#    #local -r id="${BASH_REMATCH[4]}"
#    #[ -e "$id" ] && return
#    #echo "$1" >&2
#    local t="$(ucurl "$1" | tr -d '\t\n\r\a\v')" t2
#    local next path
#
#    {
#    echo "$1" #link
#    echo "$id" #id
#    echo "$(hgrep -E '.* .maintitle; a href="(viewtopic\.php|topic[-_]).*" | "%i\n",
#        .* #pageheader; h[1-6]; .* @M"<" | "%i\n",
#        div #page-body; h[1-6] @l[1]; a href="\./viewtopic\.php.*" | "%i\n"' <<< "$t" | sed 's/<[^>]*>//g;q')" #title
#    echo "$(hgrep -E 'td -.catHead; .* .nav @m"(->|&raquo;)"; a -href="#.*" @l[1] @M"<" | "%i\t",
#        {.* .breadcrumbs, .* .bc-header} ; a -href="#.*" @l[1] | "%i\t"' <<< "$t" | awk -v RS='\t' '{ if (i[$0]) {exit} else {i[$0]=1;printf("%s\t",$0)}}')" #path
#
#    #hgrep -E 'table .forumline; tr @l[1] @m"<td class=\"row[0-9]\""' <<< "$t" | sed 'N;s/\n/ /' 1 2 4 10
#
#
#
#    for i in $(hgrep -E 'table .forumline; tr @l[1] @m"<td class=\"row[0-9]\""' <<< "$t" | sed 'N;s/\n/ /') 
#    do
#        hgrep 'a name="[0-9]*" | "%(name)a\n"' <<< "$i" #postid
#        hgrep 'span .postdetails @M"<a" | "%i\n"' <<< "$i" | sed 's/^[^:]*: //;s/<.*//' #date
#        t2="$(hgrep 'span .postbody | "%i\n"' <<< "$i")"
#        head -n 1 <<< "$t2" #content
#        tail -n 1 <<< "$t2" #signature
#        hgrep 'span .gensmall' <<< "$i" #note
#        hgrep 'span .postdetails; img src | "%(src)a\n"' <<< "$i" #avatar
#        hgrep -E 'span .name; (b|strong) | "%i\n"' <<< "$i" #user
#        hgrep -E 'span .postdetails; a href=".*(&amp;|&)u=[0-9]*.*" | "%(href)a\n"' <<< "$i" | sed -E 's/.*(&amp;|&)u=([0-9]*).*/\2/;q' #userid
#        hgrep -E 'span .postdetails @m"<a" | "%i\n"' <<< "$i" | sed -E 's/^ *<br \/>//;s/<br \/> *$//;s/(<br \/>)+/\t/g;s/(^|\t)<[^\t]*\t//; s/<!--[^>]*-->//g; s/(^|\t)([^\t:]+(\t|$))/\1Rank: \2/;s/(^|\t)([^:]+): ([^\t]+)/\1\2^G\3/g' #userinfo
#    done
#
#    hgrep -E 'div #pagecontent; table @l[1]; tr ."row[0-9]" @l[1]' | sed 'N;N;s/\n/ /g'
#    hgrep -E '(span|div) .postbody' <<< "$i"
# #not implemented yet}

get_forum() {
    local t t2 next
    echo "$1" >&2
    t="$(ucurl "$1" | tr -d '\n\t\r')"
    while :
    do
        for i in $(hgrep 'li; a .forumtitle href | "%(href)a\n"' <<< "$t" | sed 's/^\.\///;s/&amp;/\&/g')
        do
            get_forum "$url/$i"
        done
        for i in $(hgrep 'li; a .topictitle href | "%(href)a\n"' <<< "$t" | sed 's/^\.\///;s/&amp;/\&/g')
        do
            [ "$(jobs | wc -l)" -gt "$maxprocs" ] && wait %%
            get_topic "$url/$i" &
        done
        t2="$(hgrep 'a href rel=next | "%(href)a\n"' <<< "$t" | sed 's/^\.\///;s/&amp;/\&/g;q')"
        [ -z "$t2" ] && t2="$(hgrep -E 'div .topic-actions; div .pagination @l[1]; span @l[1]; (a|strong) -href=# | "%(href)a\n"' <<< "$t" | sed -n '/^$/{N;s/\n//;s/&amp;/\&/g;s/^\.\///;p;q}')"
        next="$url/$t2"
        grep -q '&start=[0-9]*$' <<< "$next" || break
        echo "$next" >&2
        t="$(ucurl "$next" | tr -d '\t\r\a')";
    done
    wait
}


baseurl() {
    local base="$(dirname "$1")"
    grep -Eq '^http(s)?://([a-zA-Z0-9-]+\.)+[a-zA-Z]+/?$' <<< "$1" && base="$(sed 's#/$##' <<< "$1")"
    echo "$base"
}

usage() {
    printf '%s [OPTION]... [URL]...\n' "${0##*/}"
    printf 'Download, convert to json and save phpbb forums from URL.\n'
    printf 'The 1.x versions of phpbb are not supported yet.\n\n'
    printf 'Options:\n  -d,\t--dir DIR\t\tchange directory to DIR\n'
    printf '  -p,\t--max-procs NUM\t\tset number of processes to run at a time\n'
    printf '  -b,\t--cookie DATA|FILENAME\tpass cookie to curl\n'
    printf '  -t,\t--topic URL\t\tpass URL as topic link\n'
    printf '  -f,\t--forum URL\t\tpass URL as forum link\n'
    printf '  -h,\t--help\t\t\tshow this message\n'
}

[ "$#" -eq 0 ] && { usage >&2; exit 1; }

while [ "$#" -gt 0 ]
do
    case "$1" in
        -d|--dir) cd "$2" || break; shift;;
        -t|--topic)
            url="$(baseurl "$2")"
            get_topic "$2"
            shift;;
        -f|--forum)
            url="$(baseurl "$2")"
            get_forum "$2"
            shift;;
        -b|--cookie) _cookies="$2"; shift;;
        -p|--max-procs) maxprocs="$2"; shift;;
        -h|--help) usage >&2; exit;;
        -*) usage >&2; exit 1;;
        *) break;;
    esac
    shift
done

while [ "$#" -gt 0 ]
do
    url="$(baseurl "$1")"
    case "$1" in
        http?(s)://+(+([[:alnum:]-]).)+([[:alpha:]])/?(*/)viewtopic.php*[\&\?]t=+([[:digit:]])*)
            get_topic "$1";;
        http?(s)://+(+([[:alnum:]-]).)+([[:alpha:]])/?(*/)viewforum.php*)
            get_forum "$1";;
        http?(s)://+(+([[:alnum:]-]).)+([[:alpha:]])/?(*/)index.php*)
            get_forum "$1";;
        http?(s)://+(+([[:alnum:]-]).)+([[:alpha:]])*)
            get_forum "$1";
    esac
    shift
done
